---
layout: post
title:  wget
category: ConsoleUtilities
---

### Опции:
 
    -V (--version) - вывести версию программы
    -h (--help) - вывести справку
    -b (--background) - работать в фоновом режиме
    -o файл (--out-file) - указать лог файл
    -d (--debug) - включить режим отладки
    -v (--verbose) - выводить максимум информации о работе утилиты
    -q (--quiet) - выводить минимум информации о работе
    -i файл (--input-file) - прочитать URL из файла
    --force-html - читать файл указанный в предыдущем параметре как html
    -t (--tries) - количество попыток подключения к серверу
    -O файл (--output-document) - файл в который будут сохранены полученные данные
    -с (--continue) - продолжить ранее прерванную загрузку
    -S (--server-response) - вывести ответ сервера
    --spider - проверить работоспособность URL
    -T время (--timeout) - таймаут подключения к серверу
    --limit-rate - ограничить скорость загрузки
    -w (--wait) - интервал между запросами
    -Q (--quota) - максимальный размер загрузки
    -4 (--inet4only) - использовать протокол ipv4
    -6 (--inet6only) - использовать протокол ipv6
    -U (--user-agent)- строка USER AGENT отправляемая серверу
    -r (--recursive)- рекурсивная работа утилиты
    -l (--level) - глубина при рекурсивном сканировании
    -k (--convert-links) - конвертировать ссылки в локальные при загрузке страниц
    -P (--directory-prefix) - каталог, в который будут загружаться файлы
    -m (--mirror) - скачать сайт на локальную машину
    -p (--page-requisites) - во время загрузки сайта скачивать все необходимые ресурсы
____________________________

#### 1. Загрузка файла:

Команда **wget linux** скачает один файл и сохранит его в текущей директории. Во время загрузки мы 
увидим прогресс, размер файла, дату его последнего изменения, а также скорость загрузки:

>wget http://ftp.gnu.org/gnu/wget/wget-1.5.3.tar.gz

#### 2. Сохранить файл с другим именем:

Опция ***-О*** позволяет задать имя сохраняемому файлу, например, скачать файл **wget** с именем 
**wget.
zip**:

>wget -O wget.zip http://ftp.gnu.org/gnu/wget/wget-1.5.3.tar.gz

#### 3. Скачать несколько файлов:

Вы можете скачать несколько файлов одной командой даже по разным протоколам, просто указав их 
**URL**:

>wget http://ftp.gnu.org/gnu/wget/wget-1.5.3.tar.gz ftp://ftp.gnu.org/gnu/wget/wget-1.10.1.tar.
> gz.sig

#### 4. Взять **URL** из файла:

Вы можете сохранить несколько**URL** в файл, а затем загрузить их все, передав файл опции ***-i***. 
Например создадим файл tmp.txt, со ссылками для загрузки **wget**, а затем скачаем его:

>wget -i /wget/tmp.txt

#### 5. Продолжить загрузку:

Утилита ***wget linux*** рассчитана на работу в медленных и нестабильных сетях. Поэтому если вы 
загружали большой файл, и во время загрузки было потеряно соединение, то вы можете скачать файл 
***wget*** с помощью опции ***-c***.

>wget -c http://ftp.gnu.org/gnu/wget/wget-1.5.3.tar.gz

#### 6. Загрузка файлов в фоне:

Опция ***-b*** заставляет программу работать в фоновом режиме, весь вывод будет записан в лог файл, 
для настройки лог файла используются специальные ключи wget:

>wget -b -o ~/wget.log http://ftp.gnu.org/gnu/wget/wget-1.5.3.tar.gz

#### 7. Ограничение скорости загрузки:

Команда **wget linux** позволяет не только продолжать загрузку файлов, но и ограничивать скорость 
загрузки. Для этого есть опция --limit-rate. Например ограничим скорость до 100 килобит:

>wget --limit-rate=100k ftp://ftp.iinet.net.au/debian/debian-cd/8.4.0/amd64/iso-dvd/debian-8.4.
> 0-amd64-DVD-1.iso

#### 9. Загрузить и выполнить:

Вы, наверное, уже видели такие команды. wget позволяет сразу же выполнять скачанные скрипты:

>wget -O - http://сайт/скрипт.sh | bash

Если опции ***-O*** не передать аргументов, то скачанный файл будет выведен в стандартный вывод, 
затем 
мы его можем перенаправить с интерпретатор bash, как показано выше.  

#### 10. Сохранить файл в папке:

 По умолчанию wget сохраняет файл в текущую папку, но это поведение очень легко изменить с 
 помощью опции ***-P***:

>wget -P ~/Downloads/ http://ftp.gnu.org/gnu/wget/wget-1.5.3.tar.gz

#### 11. Скачать сайт:

**Wget** позволяет не только скачивать одиночные файлы, но и целые сайты, чтобы вы могли их потом 
просматривать в офлайне. Использование wget, чтобы скачать сайт в **linux** выглядит вот так:

>wget --mirror -p --convert-links -P ./<Local-Folder> аддресс_сайт
________________________________________________________________________________________________

Чтобы скачать сайт целиком с помощью wget нужно выполнить команду:

>http://site.com/

 После выполнения данной команды в директорию site.com будет загружена локальная копия сайта 
 ***http://site.com***. Чтобы открыть главную страницу сайта нужно открыть файл***index.html***.
Рассмотрим используемые параметры:

> -r	—	указывает на то, что нужно рекурсивно переходить по ссылкам на сайте, чтобы скачивать 
 страницы.

>-k	—	используется для того, чтобы wget преобразовал все ссылки в скаченных файлах таким 
 образом, чтобы по ним можно было переходить на локальном компьютере (в автономном режиме).

 >-p	—	указывает на то, что нужно загрузить все файлы, которые требуются для отображения 
 страниц (изображения, css и т.д.).

> -l	—	определяет максимальную глубину вложенности страниц, которые wget должен скачать (по 
  умолчанию значение равно 5, в примере мы установили 7). В большинстве случаев сайты имеют 
  страницы с большой степенью вложенности и wget может просто «закопаться», скачивая новые 
 страницы. Чтобы этого не произошло можно использовать параметр -l.

> -E	—	добавлять к загруженным файлам расширение .html.

> -nc	—	при использовании данного параметра существующие файлы не будут перезаписаны. Это 
 удобно, когда нужно продолжить загрузку сайта, прерванную в предыдущий раз.
 